{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96800 entries, 0 to 96799\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   xAcc    96800 non-null  float64\n",
      " 1   yAcc    96800 non-null  float64\n",
      " 2   zAcc    96800 non-null  float64\n",
      " 3   xGyro   96800 non-null  float64\n",
      " 4   yGyro   96800 non-null  float64\n",
      " 5   zGyro   96800 non-null  float64\n",
      " 6   label   96800 non-null  object \n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the features as we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every row is an observation of length 400 x 3 x 2\n",
    "\n",
    "num_rows = data.shape[0]\n",
    "# Set the step size to select every 400 rows\n",
    "step = 400\n",
    "\n",
    "# Create a range of indices to select rows in chunks of 400\n",
    "indices = np.arange(0, num_rows, step)\n",
    "\n",
    "# Create a list to store the transposed data\n",
    "transposed_data = []\n",
    "new_data = pd.DataFrame()\n",
    "# Iterate over the original columns\n",
    "for col in data.columns:\n",
    "    if col != \"label\":\n",
    "        # Extract values from the column and reshape into chunks of 400 rows\n",
    "        column_values = data[col].values\n",
    "        # reshaped_values = column_values[indices]\n",
    "        # Split the list into chunks of 400 values\n",
    "        chunk_size = 400\n",
    "        chunks = [column_values[i:i + chunk_size] for i in range(0, len(column_values), chunk_size)]\n",
    "\n",
    "        # Create a DataFrame\n",
    "        tmp = pd.DataFrame(chunks, columns=[f'{col}_{i+1}' for i in range(chunk_size)])\n",
    "        new_data = pd.concat([new_data, tmp], axis=1)\n",
    "\n",
    "labels = np.array(data.label.iloc[np.arange(0,data.shape[0], 400)])\n",
    "new_data[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xAcc_1</th>\n",
       "      <th>xAcc_2</th>\n",
       "      <th>xAcc_3</th>\n",
       "      <th>xAcc_4</th>\n",
       "      <th>xAcc_5</th>\n",
       "      <th>xAcc_6</th>\n",
       "      <th>xAcc_7</th>\n",
       "      <th>xAcc_8</th>\n",
       "      <th>xAcc_9</th>\n",
       "      <th>xAcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>zGyro_392</th>\n",
       "      <th>zGyro_393</th>\n",
       "      <th>zGyro_394</th>\n",
       "      <th>zGyro_395</th>\n",
       "      <th>zGyro_396</th>\n",
       "      <th>zGyro_397</th>\n",
       "      <th>zGyro_398</th>\n",
       "      <th>zGyro_399</th>\n",
       "      <th>zGyro_400</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.99</td>\n",
       "      <td>6.51</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.34</td>\n",
       "      <td>6.49</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.27</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.79</td>\n",
       "      <td>6.72</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.89</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.48</td>\n",
       "      <td>6.45</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.70</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.64</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.92</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.79</td>\n",
       "      <td>5.88</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.98</td>\n",
       "      <td>...</td>\n",
       "      <td>22.77</td>\n",
       "      <td>23.86</td>\n",
       "      <td>26.43</td>\n",
       "      <td>34.36</td>\n",
       "      <td>39.92</td>\n",
       "      <td>39.67</td>\n",
       "      <td>37.78</td>\n",
       "      <td>38.09</td>\n",
       "      <td>36.19</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.88</td>\n",
       "      <td>6.49</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.09</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.41</td>\n",
       "      <td>12.76</td>\n",
       "      <td>7.47</td>\n",
       "      <td>6.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>-4.94</td>\n",
       "      <td>-4.21</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>1.40</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.56</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.35</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.16</td>\n",
       "      <td>12.62</td>\n",
       "      <td>9.95</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.78</td>\n",
       "      <td>-24.23</td>\n",
       "      <td>-29.91</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>-20.26</td>\n",
       "      <td>-9.89</td>\n",
       "      <td>-9.58</td>\n",
       "      <td>-18.62</td>\n",
       "      <td>-35.58</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>6.59</td>\n",
       "      <td>6.94</td>\n",
       "      <td>7.21</td>\n",
       "      <td>6.72</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.51</td>\n",
       "      <td>6.77</td>\n",
       "      <td>8.18</td>\n",
       "      <td>10.87</td>\n",
       "      <td>8.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.47</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>4.27</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>-15.20</td>\n",
       "      <td>-17.40</td>\n",
       "      <td>-12.88</td>\n",
       "      <td>-16.66</td>\n",
       "      <td>-23.13</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>6.86</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.63</td>\n",
       "      <td>6.60</td>\n",
       "      <td>6.41</td>\n",
       "      <td>7.32</td>\n",
       "      <td>9.05</td>\n",
       "      <td>9.84</td>\n",
       "      <td>8.77</td>\n",
       "      <td>7.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.71</td>\n",
       "      <td>-22.28</td>\n",
       "      <td>-26.18</td>\n",
       "      <td>-31.07</td>\n",
       "      <td>-37.66</td>\n",
       "      <td>-48.46</td>\n",
       "      <td>-50.66</td>\n",
       "      <td>-35.52</td>\n",
       "      <td>-21.06</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>6.78</td>\n",
       "      <td>8.19</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.53</td>\n",
       "      <td>6.69</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8.30</td>\n",
       "      <td>7.21</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.70</td>\n",
       "      <td>...</td>\n",
       "      <td>16.24</td>\n",
       "      <td>18.68</td>\n",
       "      <td>18.80</td>\n",
       "      <td>18.31</td>\n",
       "      <td>14.28</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.33</td>\n",
       "      <td>15.14</td>\n",
       "      <td>24.60</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>8.42</td>\n",
       "      <td>8.20</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.13</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.16</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.78</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.08</td>\n",
       "      <td>-10.86</td>\n",
       "      <td>-10.62</td>\n",
       "      <td>-5.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>11.35</td>\n",
       "      <td>15.69</td>\n",
       "      <td>18.62</td>\n",
       "      <td>22.95</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>11.33</td>\n",
       "      <td>11.85</td>\n",
       "      <td>8.37</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.83</td>\n",
       "      <td>8.30</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.71</td>\n",
       "      <td>8.64</td>\n",
       "      <td>8.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.59</td>\n",
       "      <td>-46.45</td>\n",
       "      <td>-32.90</td>\n",
       "      <td>-32.04</td>\n",
       "      <td>-35.77</td>\n",
       "      <td>-34.55</td>\n",
       "      <td>-28.02</td>\n",
       "      <td>-22.52</td>\n",
       "      <td>-19.23</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 2401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     xAcc_1  xAcc_2  xAcc_3  xAcc_4  xAcc_5  xAcc_6  xAcc_7  xAcc_8  xAcc_9  \\\n",
       "0      6.99    6.51    6.22    6.34    6.49    6.55    6.27    6.67    6.79   \n",
       "1      6.89    6.61    6.48    6.45    6.75    6.90    6.70    6.55    6.47   \n",
       "2      5.92    5.89    5.83    5.89    5.94    5.90    5.79    5.88    6.02   \n",
       "3      6.88    6.49    6.41    6.09    5.62    5.67    7.41   12.76    7.47   \n",
       "4      6.56    6.12    6.17    6.41    6.35    5.88    5.36    5.16   12.62   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "237    6.59    6.94    7.21    6.72    6.58    6.51    6.77    8.18   10.87   \n",
       "238    6.86    6.81    6.63    6.60    6.41    7.32    9.05    9.84    8.77   \n",
       "239    6.78    8.19    7.49    7.53    6.69    8.30    8.30    7.21    6.68   \n",
       "240    8.42    8.20    7.70    8.13    8.70    8.70    8.16    7.48    7.65   \n",
       "241   11.33   11.85    8.37    7.95    6.83    8.30    9.00    8.71    8.64   \n",
       "\n",
       "     xAcc_10  ...  zGyro_392  zGyro_393  zGyro_394  zGyro_395  zGyro_396  \\\n",
       "0       6.72  ...      -0.67      -1.10      -1.34      -1.28      -1.04   \n",
       "1       6.64  ...      -0.43      -0.73      -0.85      -1.04      -1.04   \n",
       "2       5.98  ...      22.77      23.86      26.43      34.36      39.92   \n",
       "3       6.55  ...       0.06       3.05       1.46      -3.05      -3.78   \n",
       "4       9.95  ...     -16.78     -24.23     -29.91     -28.75     -20.26   \n",
       "..       ...  ...        ...        ...        ...        ...        ...   \n",
       "237     8.51  ...      -6.47      -1.59       4.27      -4.70     -15.20   \n",
       "238     7.39  ...     -14.71     -22.28     -26.18     -31.07     -37.66   \n",
       "239     6.70  ...      16.24      18.68      18.80      18.31      14.28   \n",
       "240     7.78  ...      -7.08     -10.86     -10.62      -5.62       1.71   \n",
       "241     8.29  ...     -53.59     -46.45     -32.90     -32.04     -35.77   \n",
       "\n",
       "     zGyro_397  zGyro_398  zGyro_399  zGyro_400  label  \n",
       "0        -0.98      -0.98      -0.98      -1.10   fall  \n",
       "1        -1.34      -0.79      -0.92      -0.67   fall  \n",
       "2        39.67      37.78      38.09      36.19   fall  \n",
       "3        -4.94      -4.21      -2.56       1.40   fall  \n",
       "4        -9.89      -9.58     -18.62     -35.58   fall  \n",
       "..         ...        ...        ...        ...    ...  \n",
       "237     -17.40     -12.88     -16.66     -23.13  light  \n",
       "238     -48.46     -50.66     -35.52     -21.06  light  \n",
       "239       5.86       4.33      15.14      24.60  light  \n",
       "240      11.35      15.69      18.62      22.95  light  \n",
       "241     -34.55     -28.02     -22.52     -19.23  light  \n",
       "\n",
       "[242 rows x 2401 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n",
      "400\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'rfall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m     gyr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(gyr)\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m gyr\n\u001b[1;32m---> 36\u001b[0m new_data\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: acc_sum(x), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\engri\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\engri\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\engri\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\engri\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[94], line 36\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     32\u001b[0m     gyr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(gyr)\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m gyr\n\u001b[1;32m---> 36\u001b[0m new_data\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: acc_sum(x), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[94], line 18\u001b[0m, in \u001b[0;36macc_sum\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macc_sum\u001b[39m(row):\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m     \u001b[39m# Split the list into chunks of 400 values\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     n_chunks \u001b[39m=\u001b[39m \u001b[39m2400\u001b[39m\u001b[39m/\u001b[39m\u001b[39m400\u001b[39m\n\u001b[1;32m---> 18\u001b[0m     chunks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray_split(np\u001b[39m.\u001b[39;49marray(row\u001b[39m.\u001b[39;49mvalues[:\u001b[39mlen\u001b[39;49m(row\u001b[39m.\u001b[39;49mvalues)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m), n_chunks)\n\u001b[0;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(chunks[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[0;32m     20\u001b[0m     acc \u001b[39m=\u001b[39m chunks[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m chunks[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m chunks[\u001b[39m2\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'rfall'"
     ]
    }
   ],
   "source": [
    "# every row is an observation of length 400 x 3 x 2\n",
    "\n",
    "num_rows = new_data.shape[0]\n",
    "# Set the step size to select every 400 rows\n",
    "step = 400\n",
    "\n",
    "# Create a range of indices to select rows in chunks of 400\n",
    "indices = np.arange(0, num_rows, step)\n",
    "\n",
    "# Create a list to store the transposed data\n",
    "new_data2 = pd.DataFrame()\n",
    "# Iterate over the original columns\n",
    "\n",
    "def acc_sum(row):\n",
    "\n",
    "    # Split the list into chunks of 400 values\n",
    "    n_chunks = 2400/400\n",
    "    chunks = np.array_split(np.array(row.values[:len(row.values)-1], dtype=float), n_chunks)\n",
    "    print(len(chunks[-1]))\n",
    "    acc = chunks[0]**2 + chunks[1]**2 + chunks[2]**2\n",
    "    acc = np.sqrt(acc)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def gyr_sum(vector):\n",
    "\n",
    "    chunk_size = 400\n",
    "    chunks = [np.array(vector[i:i + chunk_size], dtype=float) for i in range(0, len(vector)-1, chunk_size)]\n",
    "\n",
    "    gyr = chunks[3]**2 + chunks[4]**2 + chunks[5]**2\n",
    "    gyr = np.sqrt(gyr)\n",
    "\n",
    "    return gyr\n",
    "\n",
    "new_data.apply(lambda x: acc_sum(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import *\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import periodogram\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def maxbin(row: Union[List[float], np.ndarray], plot: bool, n_bins: int = 10) -> List[float]:\n",
    "    \"\"\"\n",
    "    Divide the data into a specified number of bins and calculate the maximum value for each bin.\n",
    "\n",
    "    Args:\n",
    "        row (list or array): The data to be divided into bins.\n",
    "        num_bins (int, optional): The number of bins to divide the data into. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the maximum value for each bin.\n",
    "    \"\"\"\n",
    "    n = len(row)\n",
    "    freq = list(fftfreq(n*2))\n",
    "    step = n//n_bins\n",
    "    max_values = []\n",
    "    max_freqs = []\n",
    "    for i in range(0, n+1, step):\n",
    "        if i==0:\n",
    "            prec = i\n",
    "            continue\n",
    "        mm = max(row[prec: i])\n",
    "        max_values.append(mm)\n",
    "        max_freqs.append(freq[list(row).index(mm)])\n",
    "        prec = i\n",
    "    if plot:\n",
    "        return max_freqs, max_values\n",
    "    else:\n",
    "        return max_values\n",
    "\n",
    "\n",
    "def fourier_magnitudes(signal: np.ndarray, n_bins: int = 10, plot: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function takes a matrix (signal) which contains a time series for each row.\n",
    "    It applies the Fast Fourier Transform and uses the get_max_per_bin function to find the maximum peaks for each bin of the arrays of the power spectrum for the FFT.\n",
    "\n",
    "    Args:\n",
    "        signal (np.ndarray): The input matrix, where each row represents a time series.\n",
    "        num_bins (int, optional): The number of bins to divide the data into. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The maximum peaks for each bin of the arrays of the power spectrum for the FFT.\n",
    "    \"\"\"\n",
    "    signal= np.array(signal)\n",
    "    # let's calculate the FFT\n",
    "    magnitudes = np.apply_along_axis(fft, 0, signal) \n",
    "    # extract just the first half of power spectrum and discover the peaks\n",
    "    if len(magnitudes.shape)==1:\n",
    "        magnitudes=magnitudes[:((magnitudes.shape[0])//2)]\n",
    "    else:\n",
    "        magnitudes=magnitudes[:((magnitudes.shape[0])//2),:]\n",
    "    # apply power spectrum formula\n",
    "    magnitudes = np.abs(magnitudes)**2 \n",
    "    # take the peaks for each bin\n",
    "    peaks = np.apply_along_axis(lambda x: maxbin(x, plot, n_bins), 0, magnitudes)\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "\n",
    "def psd_stats(signal: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function takes a matrix (signal) which contains a time series for each row.\n",
    "    It calculates the Power Spectral Density (PSD) from the signal and returns three different summary statistics\n",
    "    from the distribution of PSD: the median, the mean absolute deviation, and the skewness (third moment).\n",
    "\n",
    "    Args:\n",
    "        signal (np.ndarray): The input matrix, where each row represents a time series.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array containing the median, mean absolute deviation, and skewness of the Power Spectral Density.\n",
    "    \"\"\"\n",
    "    signal= np.array(signal)\n",
    "    # let's calculate the Power Spectral Density\n",
    "    psd = np.array(np.abs(np.apply_along_axis(periodogram, 0, signal)[1]), dtype=np.float64)\n",
    "    \n",
    "    # extract our main summaries from the distribution\n",
    "    median = np.median(psd, axis=0)\n",
    "    # calculate the third moment (skewness)\n",
    "    third_moment = skew(psd, axis=0)\n",
    "    # calculate the mean absolute deviation\n",
    "    mad = np.mean(np.abs(psd - np.mean(psd, axis=0)), axis = 0)\n",
    "    \n",
    "    return np.array([median, mad, third_moment])\n",
    "\n",
    "\n",
    "def acf(signal: np.ndarray, n_lags: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function takes a matrix (signal) which contains a time series for each row.\n",
    "    It calculates the auto-correlation for different lags.\n",
    "\n",
    "    Args:\n",
    "        signal (np.ndarray): The input matrix, where each row represents a time series.\n",
    "        num_lags (int, optional): The number of lags to calculate the auto-correlation for. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The auto-correlation for each time series in the input matrix.\n",
    "    \"\"\"\n",
    "    signal= np.array(signal)\n",
    "    autocorrelations = np.apply_along_axis(lambda x: sm.tsa.acf(x, nlags=n_lags), 0, signal)\n",
    "\n",
    "    return autocorrelations\n",
    "\n",
    "\n",
    "def adjust_df(s: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a pandas Series, explodes and transposes it, and returns it as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): The input pandas Series.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The adjusted DataFrame.\n",
    "    \"\"\"\n",
    "    df_list = [pd.DataFrame(matrix, index=[index]*len(matrix)) for index, matrix in s.items()]\n",
    "    new_df = pd.concat(df_list, axis=0)\n",
    "    new_df.columns = range(new_df.shape[1])\n",
    "    new_df = new_df.T\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def get_season(date):\n",
    "    if date.month in [3, 4, 5]:\n",
    "        return 1 # spring\n",
    "    elif date.month in [6, 7, 8]:\n",
    "        return 2 # summer\n",
    "    elif date.month in [9, 10, 11]:\n",
    "        return 3 # autumn\n",
    "    else:\n",
    "        return 4 # winter\n",
    "    \n",
    "\n",
    "def preproc(df, n_bins=10, n_lags=10):\n",
    "    \n",
    "    # group timeseries by accelerometer (device)\n",
    "    group_dict = {}\n",
    "    for col in df.columns:\n",
    "        match = re.match(\"^([A-Z1-9]{4})\", col)\n",
    "        group_dict[col] = match.group() if match else None\n",
    "\n",
    "    new_df = df.T.groupby(group_dict, axis=0)\n",
    "\n",
    "    # evaluate max magnitudes (intesities of the frequencies from Fourier Fast transform) for each observation for each accelerometer\n",
    "    magns = new_df.apply(lambda x: fourier_magnitudes(x, n_bins))\n",
    "\n",
    "    # change col names of our dataframe of magnitudes\n",
    "    existing_columns = magns.columns\n",
    "    # generate a list of new column names\n",
    "    new_columns = []\n",
    "    i=1\n",
    "    for j,col_name in enumerate(existing_columns):\n",
    "        if ((j+1)%(n_bins+1)) == 0:\n",
    "            i=1\n",
    "        new_columns.append(f\"{col_name}_mag_max_{i}\")\n",
    "        i+=1\n",
    "    magns.columns = new_columns\n",
    "\n",
    "    new_df = adjust_df(magns)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\engri\\AppData\\Local\\Temp\\ipykernel_5748\\310717205.py:152: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  magns = new_df.apply(lambda x: fourier_magnitudes(x, n_bins))\n"
     ]
    }
   ],
   "source": [
    "prova = preproc(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[242 rows x 0 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
