Articles for fall detection with MACHINE LEARNING:

- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7697900/
- A Wavelet-Based Approach to Fall Detection -> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4482005/
- Naive Bayes and SVM --> https://www.hindawi.com/journals/bmri/2020/2167160/
- Decision tree, Naive Bayes and SVM --> https://www.mdpi.com/2076-3417/13/8/4988#B14-applsci-13-04988

Articles for fall detection with DEEP LEARNING:
>- the best article found!!!!!!!!!!!!!! --> https://www.mdpi.com/2076-3417/13/8/4988
>- techniques for better results---> pplying data augmentation techniques: adding gaussian noise with standard deviation to the input sequence | scaling the original sequence by a random value in the range 0.7 and 1.1 (https://www.sciencedirect.com/science/article/pii/S0169260719311770)
>- CNN+LSTM

# Plots:
>- adapt the plots from signle samples for each class to class plots with snsn mean and std
>- comparative plots of performaces of machine learing algortihms --> ROC curve, Precision-Recall curve, confusion matrix (or better report accuracy, sensitivity and specificity


# preporc and collection:
>- report the effective sampling frequency in Hz
>- speak about the WINDOW for signal processing
>- we have to say that we excluded the alpha degree (reported in this article: https://www.ijrte.org/wp-content/uploads/papers/v8i3/C3877098319.pdf) since we cannot assume a fixed orientation fo the device during data collection or in test phase
>- wavelets continuous transform
>- justify fft peaks
>- CWT coefficients with mother wavelet
>- also add the CALIBRATION problem and the assumption of bias exclusion w.r.t. mother wavelet
>- specify the number of people used to collect data and the number of examples with a brief view of data before preproc
>- report use cases and introduce possible applications (for example the video with air bag jacket)


# Supervised ML algorithms:
>- knn vs logistic (cap 1 ESL)
>- naive bayes vs logistic?
>- justify logistic CV results
>- try different regression splines (always ESL) and motivate the exclusion/inclusion of the model
>- announce the random forest (ensamble?) world and motivate the overperformance for the XGBoost
>- SVM???

# Unsupervised algorithms -> justify our choice of classes:
>- kmeans
>- spectral clustering?


# Deepl code:
>- https://github.com/JJN123/Fall-Detection
>- https://github.com/NathanielFelleke/TinyML-Fall-Detection/blob/main/Fall_Detection_Training.ipynb


# Further improvements:
>-  cross-dataset classifier for fall detection which is independent of the accelerometer device, the sampling rate or the length of the sequences. 

