{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "if gpu:\n",
    "  # only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpu[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpu), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xAcc</th>\n",
       "      <th>yAcc</th>\n",
       "      <th>zAcc</th>\n",
       "      <th>xGyro</th>\n",
       "      <th>yGyro</th>\n",
       "      <th>zGyro</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.99</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-7.28</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>-3.23</td>\n",
       "      <td>2.62</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.51</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-6.93</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>4.64</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.22</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-6.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>3.85</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.34</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-6.80</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>0.67</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.49</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96795</th>\n",
       "      <td>7.30</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-4.58</td>\n",
       "      <td>18.19</td>\n",
       "      <td>3.60</td>\n",
       "      <td>-35.77</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96796</th>\n",
       "      <td>7.39</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-5.05</td>\n",
       "      <td>20.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-34.55</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96797</th>\n",
       "      <td>7.52</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-5.82</td>\n",
       "      <td>22.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-28.02</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96798</th>\n",
       "      <td>7.58</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>-6.31</td>\n",
       "      <td>19.47</td>\n",
       "      <td>2.44</td>\n",
       "      <td>-22.52</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96799</th>\n",
       "      <td>7.56</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-5.89</td>\n",
       "      <td>15.56</td>\n",
       "      <td>3.91</td>\n",
       "      <td>-19.23</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96800 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xAcc  yAcc  zAcc  xGyro  yGyro  zGyro  label\n",
       "0      6.99 -0.57 -7.28  -2.75  -3.23   2.62   fall\n",
       "1      6.51 -0.75 -6.93  -0.67  -6.35   4.64   fall\n",
       "2      6.22 -0.63 -6.73   0.79  -5.49   3.85   fall\n",
       "3      6.34 -0.62 -6.80   1.59  -2.26   0.67   fall\n",
       "4      6.49 -0.39 -6.60   0.67  -0.24  -1.10   fall\n",
       "...     ...   ...   ...    ...    ...    ...    ...\n",
       "96795  7.30 -1.16 -4.58  18.19   3.60 -35.77  light\n",
       "96796  7.39 -0.37 -5.05  20.08   0.06 -34.55  light\n",
       "96797  7.52 -1.46 -5.82  22.58   0.12 -28.02  light\n",
       "96798  7.58 -2.14 -6.31  19.47   2.44 -22.52  light\n",
       "96799  7.56 -1.90 -5.89  15.56   3.91 -19.23  light\n",
       "\n",
       "[96800 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data3.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.drop(\"label\",axis=1).to_numpy().reshape(-1, 400, 6)\n",
    "labels = np.array(data.label.iloc[np.arange(0,data.shape[0], 400)])\n",
    "\n",
    "seed=1218\n",
    "sm = SMOTE(random_state=seed)\n",
    "y = labels\n",
    "X, y = sm.fit_resample(new_data.reshape(-1, 400*6), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 400, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, 400*6))\n",
    "X_test = scaler.fit_transform(X_test.reshape(-1, 400*6))\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape(-1, 400, 6)\n",
    "X_test = X_test.reshape(-1, 400, 6)\n",
    "input_shape = X_train.shape[1:]\n",
    "seq_len, n_features = input_shape\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(np.unique(y_train))\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)\n",
    "\n",
    "X_train = X_train.reshape(-1, seq_len, n_features) \n",
    "X_test = X_test.reshape(-1, seq_len, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362, 400, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: First CNN} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN neural network is designed for the classification of human daily activities and fall behaviors. It is a relatively simple architecture with convolutional and fully connected layers. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer:} \\\\\n",
    "   & \\text{Contains 32 filters with a kernel size of 3 and uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "5. & \\text{Fully Connected Layer 1:} \\\\\n",
    "   & \\text{Consists of 64 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Fully Connected Layer 2:} \\\\\n",
    "   & \\text{The output layer consists of 7 neurons with sigmoid activation, providing class probabilities.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The First Model is trained using an appropriate optimizer, and the loss function is categorical cross-entropy. The performance of the model can be evaluated based on metrics such as accuracy.\n",
    "\n",
    "This simple First Model neural network is designed to classify human activities and fall behaviors effectively by extracting basic features from accelerometer and gyroscope data and producing class probabilities using a sigmoid activation function in the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 398, 32)           608       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 199, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6368)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                407616    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 408,679\n",
      "Trainable params: 408,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "first_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 13s 52ms/step - loss: 1.0277 - accuracy: 0.6188 - val_loss: 0.6862 - val_accuracy: 0.7851\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1683 - accuracy: 0.9558 - val_loss: 0.3482 - val_accuracy: 0.8595\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9779 - val_loss: 0.1046 - val_accuracy: 0.9504\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.0880 - val_accuracy: 0.9669\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9752\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9752\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9752\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9752\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9752\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9752\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.3486e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.5551e-04 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9752\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.8521e-04 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9752\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.2996e-04 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.7674e-04 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9752\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.2926e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.8563e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.4656e-04 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9752\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.1252e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9752\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.8137e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.5405e-04 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9752\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.2704e-04 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9752\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.0487e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.8143e-04 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9752\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.6180e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.4323e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.2582e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1111e-04 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9752\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.9671e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.8408e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7033e-04 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.5805e-04 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9752\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.4793e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3802e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2851e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1973e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1194e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9752\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0387e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9613e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.8907e-04 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9752\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.8247e-04 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9752\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.7619e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7086e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6489e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9752\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5898e-04 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5498e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9752\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4941e-04 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24d7f980c10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05871253460645676, 0.9752066135406494]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-HE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CNN-HE (Convolutional Neural Network with Heuristic Enhancements)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-HE neural network is designed for the classification of human daily activities and fall behaviors. It utilizes convolutional layers and heuristic enhancements to improve accuracy in fall detection. The network structure consists of the following layers:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and inputs them into the convolution layer and bidirectional LSTM layer, respectively.} \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Performs 1D convolution with 32 filters, each with a kernel size of 5 and ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Applies max-pooling with a pool size of 2 to perform subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Convolution Layer 2:} \\\\\n",
    "   & \\text{Performs 1D convolution with 64 filters, each with a kernel size of 5 and ReLU activation function.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Applies max-pooling with a pool size of 2 to perform subsampling.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "7. & \\text{Fully Connected Layer 1:} \\\\\n",
    "   & \\text{Consists of 512 neurons with ReLU activation function.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Fully Connected Layer 2:} \\\\\n",
    "   & \\text{Consists of 7 neurons with softmax activation, which produces the final classification probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The network is trained using the Adam optimizer with a categorical cross-entropy loss function. During training, the model is trained for 70 epochs with a batch size of 64. The model's performance is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CNN-HE neural network is designed to effectively classify human activities and fall behaviors by extracting meaningful features from accelerometer and gyroscope data and utilizing heuristic enhancements to improve the accuracy of fall detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "6/6 [==============================] - 2s 223ms/step - loss: 2.3598 - accuracy: 0.4033 - val_loss: 1.9100 - val_accuracy: 0.2810\n",
      "Epoch 2/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8776 - accuracy: 0.7017 - val_loss: 0.6274 - val_accuracy: 0.8678\n",
      "Epoch 3/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3119 - accuracy: 0.9641 - val_loss: 0.3448 - val_accuracy: 0.8926\n",
      "Epoch 4/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1115 - accuracy: 0.9751 - val_loss: 0.1847 - val_accuracy: 0.9504\n",
      "Epoch 5/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0410 - accuracy: 0.9917 - val_loss: 0.1053 - val_accuracy: 0.9587\n",
      "Epoch 6/70\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9504\n",
      "Epoch 7/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9587\n",
      "Epoch 8/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9504\n",
      "Epoch 9/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9504\n",
      "Epoch 10/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.2641e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9587\n",
      "Epoch 11/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.6219e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9587\n",
      "Epoch 12/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.2867e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9587\n",
      "Epoch 13/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.5395e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9587\n",
      "Epoch 14/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.9596e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9587\n",
      "Epoch 15/70\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.5083e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9587\n",
      "Epoch 16/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.1565e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9587\n",
      "Epoch 17/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8635e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9587\n",
      "Epoch 18/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6141e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9587\n",
      "Epoch 19/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.3989e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9587\n",
      "Epoch 20/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1974e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9587\n",
      "Epoch 21/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0113e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9587\n",
      "Epoch 22/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.8403e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9587\n",
      "Epoch 23/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6686e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9587\n",
      "Epoch 24/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.5345e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9587\n",
      "Epoch 25/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4098e-04 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9587\n",
      "Epoch 26/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2799e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9587\n",
      "Epoch 27/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.1725e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9587\n",
      "Epoch 28/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0657e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9587\n",
      "Epoch 29/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.9642e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9587\n",
      "Epoch 30/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.8515e-04 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9587\n",
      "Epoch 31/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7673e-04 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9587\n",
      "Epoch 32/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.6806e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9587\n",
      "Epoch 33/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.6136e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9587\n",
      "Epoch 34/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5310e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9587\n",
      "Epoch 35/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.4707e-04 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9587\n",
      "Epoch 36/70\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.3963e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9587\n",
      "Epoch 37/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.3388e-04 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9587\n",
      "Epoch 38/70\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2848e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9669\n",
      "Epoch 39/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.2260e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9669\n",
      "Epoch 40/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.1821e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9669\n",
      "Epoch 41/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.1338e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9669\n",
      "Epoch 42/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0840e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9669\n",
      "Epoch 43/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0424e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
      "Epoch 44/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9669\n",
      "Epoch 45/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 9.6479e-05 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9669\n",
      "Epoch 46/70\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 9.2999e-05 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9669\n",
      "Epoch 47/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.9193e-05 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9669\n",
      "Epoch 48/70\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.5794e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9669\n",
      "Epoch 49/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.2749e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9669\n",
      "Epoch 50/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.9797e-05 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9669\n",
      "Epoch 51/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.6810e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9669\n",
      "Epoch 52/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4325e-05 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9669\n",
      "Epoch 53/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1867e-05 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9669\n",
      "Epoch 54/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9285e-05 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9669\n",
      "Epoch 55/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.6932e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9669\n",
      "Epoch 56/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.4714e-05 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9669\n",
      "Epoch 57/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.2647e-05 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9669\n",
      "Epoch 58/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.0715e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9669\n",
      "Epoch 59/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.8641e-05 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9669\n",
      "Epoch 60/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.7066e-05 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9669\n",
      "Epoch 61/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.5328e-05 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9669\n",
      "Epoch 62/70\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.3429e-05 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9669\n",
      "Epoch 63/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.1896e-05 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
      "Epoch 64/70\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.0494e-05 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9669\n",
      "Epoch 65/70\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.8807e-05 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9669\n",
      "Epoch 66/70\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.7528e-05 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9669\n",
      "Epoch 67/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.6241e-05 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9669\n",
      "Epoch 68/70\n",
      "6/6 [==============================] - ETA: 0s - loss: 4.6496e-05 - accuracy: 1.00 - 0s 14ms/step - loss: 4.4881e-05 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9669\n",
      "Epoch 69/70\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3633e-05 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n",
      "Epoch 70/70\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.2484e-05 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ef833e340>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_he = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_he.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_he.fit(X_train, y_train, epochs=70, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-3B3Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{NN Architecture: CNN-3B3Conv (Convolutional Neural Network with Three Blocks of Three Convolutions)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-3B3Conv neural network is designed for the classification of human daily activities and fall behaviors. It consists of three blocks, each containing three 1D convolutional layers with ReLU activation functions. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Block 1:} \\\\\n",
    "   & \\text{Contains three 1D convolutional layers with 128 filters each and kernel sizes of 4. Each convolutional layer uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Block 2:} \\\\\n",
    "   & \\text{Similar to Block 1, contains three 1D convolutional layers with 128 filters each and kernel sizes of 3. All layers use ReLU activation functions.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "7. & \\text{Fully Connected Layer 1:} \\\\\n",
    "   & \\text{Consists of 128 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Dropout Layer:} \\\\\n",
    "   & \\text{Applies dropout with a probability of 0.5 to reduce overfitting.} \\\\\n",
    "\\\\\n",
    "9. & \\text{Fully Connected Layer 2:} \\\\\n",
    "   & \\text{Contains 64 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "10. & \\text{Fully Connected Layer 3:} \\\\\n",
    "    & \\text{The output layer consists of 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-3B3Conv model is trained using the Adam optimizer with categorical cross-entropy loss. During training, the model is trained for 20 epochs with a batch size of 64. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CNN-3B3Conv neural network is designed to classify human activities and fall behaviors effectively by leveraging three blocks of three convolutional layers to capture and extract relevant features from accelerometer and gyroscope data. The dropout layer helps prevent overfitting, enhancing the model's generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 3s 224ms/step - loss: 1.8915 - accuracy: 0.2707 - val_loss: 1.4394 - val_accuracy: 0.6694\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.2125 - accuracy: 0.5856 - val_loss: 0.8283 - val_accuracy: 0.7603\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.7969 - accuracy: 0.7017 - val_loss: 0.5928 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.5237 - accuracy: 0.7928 - val_loss: 0.4383 - val_accuracy: 0.8760\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.3553 - accuracy: 0.8591 - val_loss: 0.4250 - val_accuracy: 0.8760\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2094 - accuracy: 0.9392 - val_loss: 0.2541 - val_accuracy: 0.9174\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1785 - accuracy: 0.9392 - val_loss: 0.3014 - val_accuracy: 0.8843\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1531 - accuracy: 0.9503 - val_loss: 0.2131 - val_accuracy: 0.9339\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0925 - accuracy: 0.9751 - val_loss: 0.1242 - val_accuracy: 0.9587\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0624 - accuracy: 0.9834 - val_loss: 0.1337 - val_accuracy: 0.9587\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.1949 - val_accuracy: 0.9421\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0503 - accuracy: 0.9862 - val_loss: 0.1856 - val_accuracy: 0.9669\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0314 - accuracy: 0.9862 - val_loss: 0.2174 - val_accuracy: 0.9587\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.1986 - val_accuracy: 0.9421\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.1888 - val_accuracy: 0.9421\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.1471 - val_accuracy: 0.9669\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0460 - accuracy: 0.9890 - val_loss: 0.3576 - val_accuracy: 0.9008\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0417 - accuracy: 0.9890 - val_loss: 0.2213 - val_accuracy: 0.9421\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0344 - accuracy: 0.9917 - val_loss: 0.1959 - val_accuracy: 0.9421\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.1954 - val_accuracy: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f22940a30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_3B3Conv = models.Sequential([\n",
    "    layers.Conv1D(128, kernel_size=4, activation='relu', input_shape=input_shape),\n",
    "    layers.Conv1D(128, kernel_size=4, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "    ])\n",
    "\n",
    "CNN_3B3Conv.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "CNN_3B3Conv.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN EDU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CNN-EDU (Convolutional Neural Network with Educational Enhancements)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-EDU neural network is designed for the classification of human daily activities and fall behaviors. It features an architecture with multiple convolutional layers and educational enhancements to improve its performance. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Contains 16 filters with a kernel size of 5 and uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2 for subsampling.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Convolution Layer 2:} \\\\\n",
    "   & \\text{Consists of 32 filters with a kernel size of 5 and employs ReLU activation.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Convolution Layer 3:} \\\\\n",
    "   & \\text{Features 64 filters with a kernel size of 5 and ReLU activation.} \\\\\n",
    "\\\\\n",
    "7. & \\text{MaxPooling Layer 3:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Convolution Layer 4:} \\\\\n",
    "   & \\text{Incorporates 128 filters with a kernel size of 5 and ReLU activation.} \\\\\n",
    "\\\\\n",
    "9. & \\text{MaxPooling Layer 4:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "10. & \\text{Flatten Layer:} \\\\\n",
    "    & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "11. & \\text{Fully Connected Layer 1:} \\\\\n",
    "    & \\text{Consists of 128 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "12. & \\text{Dropout Layer:} \\\\\n",
    "    & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
    "\\\\\n",
    "13. & \\text{Fully Connected Layer 2:} \\\\\n",
    "    & \\text{Contains 64 neurons with ReLU activation.} \\\\\n",
    "\\\\\n",
    "14. & \\text{Fully Connected Layer 3:} \\\\\n",
    "    & \\text{The output layer consists of 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CNN-EDU model is trained using the Adam optimizer with categorical cross-entropy loss. During training, the model is trained for 100 epochs with a batch size of 16. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CNN-EDU neural network leverages multiple convolutional layers and educational enhancements to effectively classify human activities and fall behaviors by extracting meaningful features from accelerometer and gyroscope data while reducing overfitting through dropout regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 1.7035 - accuracy: 0.3260 - val_loss: 1.0621 - val_accuracy: 0.7025\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1.0431 - accuracy: 0.5580 - val_loss: 0.6676 - val_accuracy: 0.7851\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6129 - accuracy: 0.7541 - val_loss: 0.4409 - val_accuracy: 0.8430\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4159 - accuracy: 0.8481 - val_loss: 0.4282 - val_accuracy: 0.8760\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.8591 - val_loss: 0.4576 - val_accuracy: 0.7851\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.9006 - val_loss: 0.2293 - val_accuracy: 0.9339\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.1728 - accuracy: 0.9448 - val_loss: 0.1903 - val_accuracy: 0.9421\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9365 - val_loss: 0.2533 - val_accuracy: 0.8512\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.1681 - accuracy: 0.9392 - val_loss: 0.1577 - val_accuracy: 0.9174\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0738 - accuracy: 0.9834 - val_loss: 0.2303 - val_accuracy: 0.9339\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9696 - val_loss: 0.2050 - val_accuracy: 0.9256\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.2474 - val_accuracy: 0.9256\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0830 - accuracy: 0.9751 - val_loss: 0.1285 - val_accuracy: 0.9256\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 0.9779 - val_loss: 0.3069 - val_accuracy: 0.9256\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.3942 - val_accuracy: 0.8926\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.2008 - val_accuracy: 0.9091\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.1590 - val_accuracy: 0.9421\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.2134 - val_accuracy: 0.9669\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9807 - val_loss: 0.3826 - val_accuracy: 0.9669\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9972 - val_loss: 0.1808 - val_accuracy: 0.9421\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.1668 - val_accuracy: 0.9504\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.9724 - val_loss: 0.2612 - val_accuracy: 0.9339\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.9779 - val_loss: 0.0997 - val_accuracy: 0.9669\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9862 - val_loss: 0.1686 - val_accuracy: 0.9669\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9972 - val_loss: 0.3001 - val_accuracy: 0.9339\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.2302 - val_accuracy: 0.9587\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.1065 - val_accuracy: 0.9587\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.5049 - val_accuracy: 0.9256\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.1027 - val_accuracy: 0.9669\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0823 - val_accuracy: 0.9587\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9669\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.1100 - val_accuracy: 0.9669\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 0.1107 - val_accuracy: 0.9587\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9752\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.1283 - val_accuracy: 0.9587\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1389 - val_accuracy: 0.9669\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0812 - val_accuracy: 0.9752\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9890 - val_loss: 0.3246 - val_accuracy: 0.9504\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.0738 - val_accuracy: 0.9835\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.9862 - val_loss: 0.0782 - val_accuracy: 0.9669\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9751 - val_loss: 0.3496 - val_accuracy: 0.9504\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0792 - accuracy: 0.9696 - val_loss: 0.1005 - val_accuracy: 0.9669\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.1676 - accuracy: 0.9558 - val_loss: 0.2406 - val_accuracy: 0.9256\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1333 - val_accuracy: 0.9669\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9669\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.1324 - val_accuracy: 0.9669\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9669\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9669\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 0.1151 - val_accuracy: 0.9587\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9752\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9669\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9669\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 0.9972 - val_loss: 0.1568 - val_accuracy: 0.9587\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9587\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1137 - val_accuracy: 0.9504\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.2919 - val_accuracy: 0.9504\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9807 - val_loss: 0.2380 - val_accuracy: 0.9256\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0724 - accuracy: 0.9834 - val_loss: 0.3969 - val_accuracy: 0.9174\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0642 - accuracy: 0.9834 - val_loss: 0.0461 - val_accuracy: 0.9917\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0805 - val_accuracy: 0.9752\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0463 - val_accuracy: 0.9917\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.0797 - val_accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0634 - val_accuracy: 0.9835\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0273 - val_accuracy: 0.9917\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 0.0281 - val_accuracy: 0.9835\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9917\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9835\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 6.4474e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9917\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 0.0321 - val_accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9669\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9917\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9752\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.7999e-04 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9752\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.2120e-04 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9835\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.9972 - val_loss: 0.1147 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.3227e-04 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9669\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 8.5483e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9669\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 9.8988e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 8.5643e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 7.8539e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9752\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 6.7140e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.2565e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.3106e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.4317e-04 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9752\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.1714e-04 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 7.3762e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9835\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.7746e-05 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9835\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 0.9972 - val_loss: 0.2843 - val_accuracy: 0.9587\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.1633 - val_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9862 - val_loss: 0.6528 - val_accuracy: 0.8926\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9669\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.2058 - val_accuracy: 0.9669\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.1849 - val_accuracy: 0.9587\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0342 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ffa0d5550>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_EDU = models.Sequential([\n",
    "    layers.Conv1D(16, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(32, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "CNN_EDU.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "CNN_EDU.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN with LSTM layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CBAM (Convolutional-Bidirectional LSTM with Attention Mechanism)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM neural network is designed for the classification of human daily activities and fall behaviors. It combines convolutional layers, bidirectional LSTM layers, and an attention mechanism to enhance feature extraction and temporal modeling. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Contains 32 filters with a kernel size of 5 and uses the ReLU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2, strides of 2, and same padding.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Bidirectional LSTM Layer:} \\\\\n",
    "   & \\text{Consists of a bidirectional LSTM with 64 units, returning sequences to capture temporal dependencies in both directions.} \\\\\n",
    "\\\\\n",
    "5. & \\text{Flatten Layer:} \\\\\n",
    "   & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Dropout Layer:} \\\\\n",
    "   & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
    "\\\\\n",
    "7. & \\text{Fully Connected Layer:} \\\\\n",
    "   & \\text{Contains 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM model is trained using the Adam optimizer with a learning rate of 0.001. During training, the model is trained for 50 epochs with a batch size of 32. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CBAM neural network effectively combines convolutional and bidirectional LSTM layers with an attention mechanism to classify human activities and fall behaviors, capturing both spatial and temporal features from accelerometer and gyroscope data while addressing overfitting with dropout regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 7s 157ms/step - loss: 0.9334 - accuracy: 0.6464 - val_loss: 0.4515 - val_accuracy: 0.8430\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1984 - accuracy: 0.9282 - val_loss: 0.3700 - val_accuracy: 0.8347\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1075 - accuracy: 0.9641 - val_loss: 0.2603 - val_accuracy: 0.9256\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.2073 - val_accuracy: 0.9339\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0445 - accuracy: 0.9917 - val_loss: 0.3603 - val_accuracy: 0.8926\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0358 - accuracy: 0.9862 - val_loss: 0.2079 - val_accuracy: 0.9421\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9587\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9421\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9587\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9587\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9587\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9504\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9421\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9421\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9421\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 9.7984e-04 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9421\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 9.5643e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9421\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 8.9692e-04 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9421\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 7.3363e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9421\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 7.2953e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9504\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 6.6092e-04 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9504\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 5.6448e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9504\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 5.6928e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9504\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 5.4679e-04 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9504\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 4.5503e-04 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9504\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 4.5630e-04 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9504\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.9705e-04 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9504\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 4.2439e-04 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9587\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.1116e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9587\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 3.0431e-04 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9587\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.9407e-04 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9669\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.7137e-04 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9669\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.3104e-04 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9587\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.3139e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9587\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.2473e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9587\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.2831e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9669\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8335e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9669\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.6907e-04 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9669\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9669\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4433e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9669\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.3657e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9669\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.5420e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9669\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.8063e-04 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9669\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1928e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9752\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2734e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9669\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.2114e-04 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9669\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.1539e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9669\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 9.3693e-05 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9752\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.0710e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9752\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 9.7744e-05 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x250138454c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Sequential model for CBAM-IAM-CNN-BiLSTM\n",
    "CBAM = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate\n",
    "CBAM.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "CBAM.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\textbf{Neural Network Architecture: CBAM-EDU (Convolutional-Bidirectional LSTM with Educational Enhancements)} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM-EDU neural network is designed for the classification of human daily activities and fall behaviors. It combines convolutional layers, bidirectional LSTM layers, and educational enhancements, including the GELU activation function, to improve feature extraction and temporal modeling. The network structure is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "1. & \\text{Input Layer:} \\\\\n",
    "   & \\text{Accepts data from the triaxial accelerometer and triaxial angular velocity meter and has an input shape defined by } \\text{{input\\_shape}}. \\\\\n",
    "\\\\\n",
    "2. & \\text{Convolution Layer 1:} \\\\\n",
    "   & \\text{Contains 16 filters with a kernel size of 5 and uses the GELU activation function.} \\\\\n",
    "\\\\\n",
    "3. & \\text{MaxPooling Layer 1:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "4. & \\text{Convolution Layer 2:} \\\\\n",
    "   & \\text{Consists of 32 filters with a kernel size of 5 and employs the GELU activation function.} \\\\\n",
    "\\\\\n",
    "5. & \\text{MaxPooling Layer 2:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "6. & \\text{Convolution Layer 3:} \\\\\n",
    "   & \\text{Features 64 filters with a kernel size of 5 and uses the GELU activation function.} \\\\\n",
    "\\\\\n",
    "7. & \\text{MaxPooling Layer 3:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "8. & \\text{Convolution Layer 4:} \\\\\n",
    "   & \\text{Incorporates 128 filters with a kernel size of 5 and utilizes the GELU activation function.} \\\\\n",
    "\\\\\n",
    "9. & \\text{MaxPooling Layer 4:} \\\\\n",
    "   & \\text{Performs max-pooling with a pool size of 2.} \\\\\n",
    "\\\\\n",
    "10. & \\text{MaxPooling Layer 5:} \\\\\n",
    "    & \\text{Performs max-pooling with a pool size of 2, strides of 2, and same padding.} \\\\\n",
    "\\\\\n",
    "11. & \\text{Bidirectional LSTM Layer:} \\\\\n",
    "    & \\text{Consists of a bidirectional LSTM with 64 units, returning sequences to capture temporal dependencies in both directions.} \\\\\n",
    "\\\\\n",
    "12. & \\text{Flatten Layer:} \\\\\n",
    "    & \\text{Flattens the output of the previous layers for input to the fully connected layers.} \\\\\n",
    "\\\\\n",
    "13. & \\text{Dropout Layer:} \\\\\n",
    "    & \\text{Applies dropout with a probability of 0.5 to mitigate overfitting.} \\\\\n",
    "\\\\\n",
    "14. & \\text{Fully Connected Layer:} \\\\\n",
    "    & \\text{Contains 7 neurons with softmax activation, providing probabilities for 7 classes.} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The CBAM-EDU model is trained using the Adam optimizer with a learning rate of 0.001. During training, the model is trained for 50 epochs with a batch size of 32. The performance of the model is evaluated on a validation dataset, and metrics such as accuracy are computed.\n",
    "\n",
    "This CBAM-EDU neural network effectively combines convolutional and bidirectional LSTM layers with educational enhancements, including the GELU activation function, to classify human activities and fall behaviors, capturing both spatial and temporal features from accelerometer and gyroscope data while addressing overfitting with dropout regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 8s 100ms/step - loss: 1.6854 - accuracy: 0.3481 - val_loss: 1.0616 - val_accuracy: 0.5702\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7911 - accuracy: 0.7320 - val_loss: 0.5762 - val_accuracy: 0.8017\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4212 - accuracy: 0.8094 - val_loss: 0.4411 - val_accuracy: 0.8182\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2929 - accuracy: 0.8785 - val_loss: 0.3256 - val_accuracy: 0.8595\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2090 - accuracy: 0.9254 - val_loss: 0.2936 - val_accuracy: 0.8843\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1557 - accuracy: 0.9392 - val_loss: 0.2434 - val_accuracy: 0.9256\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1380 - accuracy: 0.9448 - val_loss: 0.2219 - val_accuracy: 0.9256\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1061 - accuracy: 0.9696 - val_loss: 0.2119 - val_accuracy: 0.9339\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0540 - accuracy: 0.9862 - val_loss: 0.1532 - val_accuracy: 0.9339\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0461 - accuracy: 0.9917 - val_loss: 0.1557 - val_accuracy: 0.9339\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0266 - accuracy: 0.9945 - val_loss: 0.1256 - val_accuracy: 0.9587\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0230 - accuracy: 0.9945 - val_loss: 0.1023 - val_accuracy: 0.9587\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9587\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.0691 - val_accuracy: 0.9835\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9669\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9917\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.1143 - val_accuracy: 0.9752\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0190 - accuracy: 0.9917 - val_loss: 0.1378 - val_accuracy: 0.9669\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.0405 - val_accuracy: 0.9917\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9752\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9917\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9917\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9917\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9917\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9917\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9917\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9917\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 9.7740e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9917\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 7.9993e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9917\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.6184e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9917\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 8.5236e-04 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9917\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8.9149e-04 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9917\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 4.4013e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9917\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8.0897e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9917\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 3.6888e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9917\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 5.9303e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9917\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 5.0190e-04 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9917\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.9059e-04 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9917\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 6.5894e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9835\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 4.9957e-04 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9917\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 5.6173e-04 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9917\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 2.9311e-04 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9917\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 3.3843e-04 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9917\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 2.5992e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9917\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 2.8733e-04 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9917\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 2.3017e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9917\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 4.5891e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9917\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 4.5077e-04 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 0.9917\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 3.5975e-04 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2505547d310>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Sequential model for CBAM-IAM-CNN-BiLSTM\n",
    "CBAM_EDU = models.Sequential([\n",
    "    layers.Conv1D(16, kernel_size=5, activation='gelu', input_shape=input_shape),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(32, kernel_size=5, activation='gelu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, kernel_size=5, activation='gelu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(128, kernel_size=5, activation='gelu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.MaxPooling1D(pool_size=2, strides=2, padding='same'),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate\n",
    "CBAM_EDU.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "CBAM_EDU.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
